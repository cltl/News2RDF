{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nice finds\n",
    "* http://dbpedia.org/page/WTRF-TV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need\n",
    "* topic (e.g. JEX domain classifier)\n",
    "* local news sections of websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* fix name values in json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import operator\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_dbpedia_of_publisher(publisher_string):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    sparql.setQuery(\"\"\"\n",
    "        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "        SELECT ?page\n",
    "        WHERE { ?page rdfs:label \"%s\"@en }\n",
    "    \"\"\" % publisher_string)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    \n",
    "    dbpedia_links = set()\n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        a_link = result['page']['value'] \n",
    "        if all([not a_link.startswith('http://dbpedia.org/resource/Category'),\n",
    "                a_link.startswith('http://dbpedia.org/resource/')]):\n",
    "            dbpedia_links.add(a_link)\n",
    "    return dbpedia_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_cache = False\n",
    "if use_cache:\n",
    "    with open('publishers_with_freq.json') as infile:\n",
    "        publishers_with_freq = json.load(infile)\n",
    "    \n",
    "else:\n",
    "    publishers_with_freq = defaultdict(int)\n",
    "    with open('signalmedia-1m.jsonl') as infile:\n",
    "        for line in infile:\n",
    "            article = json.loads(line)\n",
    "            publishers_with_freq[article['source']] += 1\n",
    "    with open('publishers_with_freq.json', 'w') as outfile:\n",
    "        json.dump(publishers_with_freq, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "already done: 100\n",
      "Virtual Strategy Magazine 931 set()\n",
      "\n",
      "homepage: http://virtual-strategy.com/\n",
      "dbpedia: \n",
      "wikipedia: \n",
      "dbpedia location: \n"
     ]
    }
   ],
   "source": [
    "with open('locations.json') as infile:\n",
    "    locations = json.load(infile)\n",
    "\n",
    "print()\n",
    "print('already done: %s' % (len(locations)-1))\n",
    "for source, freq in sorted(publishers_with_freq.items(),\n",
    "                           key=operator.itemgetter(1),\n",
    "                           reverse=True):\n",
    "    \n",
    "    if source in locations:\n",
    "        continue \n",
    "        \n",
    "    dbpedia_links = find_dbpedia_of_publisher(source)\n",
    "    print(source, freq)\n",
    "    for dbpedia_link in dbpedia_links:\n",
    "        print(dbpedia_link)\n",
    "    print()\n",
    "    homepage = input('homepage: ')\n",
    "    dbpedia = input('dbpedia: ')\n",
    "    wiki_uri = input('wikipedia: ')\n",
    "    dbpedia_loc = input('dbpedia location: ')\n",
    "\n",
    "    locations[source] = {'name': source}\n",
    "    \n",
    "    for key, value in [('location_dbpedia_uri', dbpedia_loc),\n",
    "                       ('dbpedia_uri', dbpedia),\n",
    "                       ('wiki_uri', wiki_uri),\n",
    "                       ('homepage', homepage)]:\n",
    "        if value:\n",
    "            locations[source][key] = value\n",
    "    \n",
    "    with open('locations.json', 'w') as outfile:\n",
    "        json.dump(locations, outfile)\n",
    "    \n",
    "    break\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
